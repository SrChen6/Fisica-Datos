Una població és un conjunt d'individus. La seva mida es representa amb una $N$ i els fenòmens d'interès (allò que volem estudiar) són les variables $x_{i}$, de manera que el conjunt de les variables és: $$X=\{x_{1},\dots,x_{n}\}$$

Depenent de $N$, la manera en que es poden presentar les dades varia.

- Mostra: quantitat petita respecte la població escollida aleatòriament que representa tota la població. S'agafen quan la població és massa gran o massa costós d'estudiar. En comptes de $N$ (per la població) s'utilitza la $n$ per la seva mida.
### Mitjana aritmètica
$$\overline X_{N}=\frac 1 N \sum\limits_{i=1}^{N}x_{i}$$ físicament és el centre de masses.

Per una variable aleatòria discreta $X\sim U(N)$ que pren algun dels valors de la població $X_{N}$: $$\overline X_{N}\equiv E(X_{N})$$
### Variancia
$$Var(X)=E((X-E(X))^{2})$$ representa com de desviades estan les dades de l'esperança.

# Tipus de dades estadístiques
## Discretes
- Ordinals: Les dades tenen un ordre
- Nominal: No hi ha ordre entre les dades

## Contínues
- Més en davant

# Variables multidimensionals
Una població d'on es vol estudiar més d'un fenomen d'interès es representa com $$(X,Y)=\{(x_{1},y_{1}),\dots,(x_{n},y_{n})\}$$

# Llei dels grans nombres
Sigui $X$ una variable aleatòria amb $E(X)<\infty$ i siguin $X_{1},\dots,X_{n}$ variables aleatòries independents idènticament distribuïdes (diversos experiments sobre la mateixa mostra), es té: $$\overline X_{n}=\frac 1n\sum\limits_{i=1}^{n}X_{i}$$ i per $n\to\infty$:$$\overline X_{n}\to\mu=E(X)$$
# Teorema central del límit
Siguin $X_{1},\dots,X_{n}\sim X$ variables aleatòries independents idènticament distribuïdes, $\mu=E(X),\,\sigma^{2}=Var(X)$ per $n$ prou gran: $$\sqrt n(\overline X_{n}-\mu)\to N(0,\sigma^{2})$$ d'on concloem que: $$\overline X_{n}\sim N(\mu,\frac{\sigma^{2}}{n})$$
# Components de l'estudi estadístic
## Inferència estadística
A partir d'una mostra, arribar a saber com es comporta la població. Si aquest últim segueix certa funció de distribució, saber quins són els seus paràmetres.

## Estimació
Estudi i resum d'una mostra utilitzant un estimador. Aquest estimador $(\hat\mu,\hat\sigma^{2})$ s'assimila a la població $(\mu,\sigma^{2})$.

## Contrast d'hipòtesi i predicció
Més profunditat a PiE 2.

# Paràmetres
Característiques numèriques d'una població $\theta$ que afecten a la funció de distribució. Per trobar $\theta$ a partir d'una mostra es fa una estimació. $$\Phi(F)=\theta$$ Per exemple: Sigui $X\sim N(\mu,\sigma^{2})$ una variables aleatòria, $\theta=(\mu,\sigma)$. Si volem trobar $\mu$ a partir de $f$: $$\Phi(F)=\int_{\mathbb R}x·Fdx$$
Per realitzar l'estimació sobre una mostra (no una variable aleatòria), s'utilitza una funció $T$: $$T(X_{1},\dots,X_{n})$$ que és un estimador $\theta (\mu,\sigma^{2})$ 
### Exemples estimadors
Per exemple, per trobar $\mu$ a partir d'un espai mostral $X_{1},\dots,X_{n}$, s'utilitza l'estadístic $$T(X_{1},\dots,X_{n})=\frac 1 n\sum _{i=1}^{n}X_{i}$$

Sigui un conjunt de dades $\{x_{1},\dots,x_{n}\}$ que sabem que ve d'una distribució $N(\mu,\sigma^{2}=1)$. Per trobar un valor a $\mu$, definim $$\hat\mu=\frac 1 n\sum\limits_{i=1}^{n}x_{i}$$ que és la mitjana de les dades.

Matemàticament: Sigui $X_{1},\dots,X_{n}$ variables aleatòries independents idènticament distribuïdes que es distribueixen com $NN(\mu,\sigma^{2}=1)$. Podem definir una nova variable aleatòria $$\overline X=\frac 1 n\sum\limits_{i=1}^{n}x_{i}$$ d'on podem trobar l'esperança $$E(\overline X)=\frac 1 n\sum\limits_{i=1}^{n}E(X)=\frac 1 n(n\mu)=\mu$$ A aquesta variable aleatòria $\overline X$ se li diu estimador.

Per diferents paràmetres es tenen diferents estimadors.


# Funció de distribució empírica
$$F_{n}(x)=\frac 1 n\{x_{i}\leq x|i=1,\dots,n\}=\frac 1 n\sum\limits_{i=1}^{n}I_{(-\infty,x]}(x_{i})$$ on $$I_{(-\infty, x]}(x_{i})=\begin{cases}
1\quad x_{i}\leq x \\
0\quad x_{i}>x
\end{cases}$$ Esglaons de salt $\frac 1 n$ a cada dada $x_{i}$.

## Propietats
$$Pr(F_{n}(x)=\frac j n)=\binom n j F(x)^{j}(1-F(x))^{n-j},\, j=0,\dots,n$$
$$\mathbb E(F_{n}(x))=F(x),Var(F_{n}(x))=\frac 1 n F(x)(1-F(x))$$
$$F_{n}(x)\to F(x)$$
$$\frac{\sqrt n(F_{n}(x)-F(x))}{\sqrt{F(x)(1-F(x))}}\to Z(0,1)$$


Per trobar $F_{n}(x)$, només hem d'agafar el nombre de dades $x_{i}$ tals que $x_{i}<x$.

Si s'utilitzen variables aleatòries en comptes de dades concretes: $$F_{n}(X)=\frac 1 n \sum\limits_{i=1}^{n}I_{A_{X}}(X_{i})$$ on $F_{n}(X)$ és una variable aleatòria

Recordem el teorema central del límit:
Si $Z_{1},\dots,Z_{n}$ són var. aleat. ident. dist. a $Z$ tal que $E(Z)=\mu$ i $Var(Z)=\sigma^{2}$ aleshores $$\sqrt n(\overline Z_{n}-\mu)\sim N(0,\sigma^{2})$$
tenim que: $$\overline Z_{n}=\frac 1 n \sum\limits_{i=1}^{n}Z_{i}$$ on $$Z_{i}=I_{A_{X}}(X_{i})=\begin{cases}
1\quad X_{i}\leq x \\
0\quad X_{i}> x
\end{cases}$$ és una variable aleatòria discreta $Z_{i}\sim Be(p)$

### Com trobar p?
Sabent que $Z_{i}$ és una Bernoulli:
$p=P(Z_{i}=1)=P(I(X_{i})=1)=P(X_{i}\leq x)=F_{X}(x)$

$E(Z_{i})=p=F_{X}(x)$ i que $Z_{i}=I_{A}(X_{i})$.
$Var(Z_{i})=F(X)(1-F(X))$ 

Ara, amb el teorema central del límit: $$\sqrt n \frac{\overline Z_{n}-F_{X}(x)}{\sqrt{F(x)(1-F(X))}}\sim N(0,1)$$
### Teorema
Sigui $F$ una funció de distribució i altres coses, aleshores $\exists X$ v.a. tal que $P(X\leq x)=F(x)$.

## Teorema de Gilvenko-Cantelli
$$\sup|F_{n}(x)-F(x)|\to0,\quad n\to\infty$$ on $F_{n}(x)$ és la funció empírica (extreta de les dades) i $F(x)$ és la funció real.