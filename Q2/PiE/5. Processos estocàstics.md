Un procés estocàstic és una seqüència $(X_{t})_{t\in T}$ on $T$ és un conjunt de temps tal que $X_{t}$ és una variable aleatòria d'un espai de probabilitats fixat $(\Omega, \mathcal A, \mathbb P)$.
- $T$ és l'espai temporal.
- $\Omega$ és l'espai mostral (AKA $S$, l'espai d'estats).
Tant $T$ com $\Omega$ poden ser contínues o discretes.

| S/T      | Discreta                   | Contínua                   |
| -------- | -------------------------- | -------------------------- |
| Discreta | Capital al jugar al casino | # alumnes en la classe     |
| Contínua | Alçada anual               | Partícula de pols voleiant |
Les nostres seran les discretes/discretes: $T\in N,t\in T\to n\in\mathbb N$ 

# Cadenes de Markov
Processos que no tenen memòria.
$(X_{n})_{n\geq 0}$ és una cadena de Markov (CdM) si $\forall n\in \mathbb N,\forall x_{o},\dots,x_{n+1}\in S$ es compleix: $$\mathbb P(X_{n+1}=x_{n+1}|X_{0}=x_{0},\dots, X_{n}=x_{n})=\mathbb P(X_{n+1}=x_{n+1}|X_{n}=x_{n})$$

> [!NOTE] Filosofia de Markov
> El futur $(n+1)$ és independent del passat $(0,1,\dots,n-1)$ si coneixem el present $n$
> -Guillem Perarnau, 2024

Observació: Si $(X_{n})_{n\geq 0}$ no és Markovià s'hi pot tornar "posant" una memòria adicional

- $X_{n}$ és homogènia si els seus canvis no depenen del valor de $n$: $$\mathbb P(X_{n+1}=j|X_{n}=i)=\mathbb P(X_{1}=j|X_{0}=i)=p_{ij}$$ on $$p_{ij}(n) =\mathbb P(X_{n}=j|X_{o}=i)\implies p_{ij}\equiv p_{ij}(1)$$ és una distribució de probabilitats.

La representació gràfica de $X_{n\geq 0}$ CdM és un graf dirigit que té vèrtexs $S$ i una aresta de $i$ a $j$ si $p_{ij}>0$ (que representa el pes).

# Matriu de transició
Sigui $(X_{n})$ CdM amb $|S|=m<\infty$, definim la matriu de transició com una matriu $m\times m$ $$P=(p_{ij})_{i,j\in S}$$
On $P$ és una matriu estocàstica ($\sum\limits files=\sum\limits columnes=1$): $$P(n)=(P_{1}(n),\dots,P_{m}(n))$$  on $P_{i}(n)=\mathbb P(X_{n}=i)$ 

- Teorema Chapman-Kolmogorov: $$p(n+1)=p(n)$$ i en particular $p(n)=p(0)P^{n}$ 

# Estructures de classes i irreductibilitat
Considerem una CdM (Cade de Markov) $S$. Siguin $i,j\in S$. Es diu que $i\to j$ estan connectats si $\exists n\in \mathbb N\quad p_{ij}(n) >0$. Si $i\to j$ i $j\to i$ estan connectats, es diu que $i\leftrightarrow j$ estan comunicats (una relació d'equivalència. És reflexiva, simètrica i transitiva).

- Classe: conjunt de tots els estats que es comuniquen entre si.
- Classe tancada: classe d'on no es pot sortir: $\forall i\in C,\quad p_{ij}(n)>0\implies j\in C$. Si només té un estat és un estat absorbent.
- El DAG (Directed Acyclic Graph) de les classes de comunicació té un vèrtex per cada classe i una aresta si és possible saltar d'una classe a una altra.

Proposició: Una CdM es pot descomposar com $C_{1}\cup C_{2}\cup\dots\cup C_{s}\cup T$ on $C_{i}$ són classes tancades ($S\geq 1$) i $T$ és la resta.

- Diem que una CdM és irreductible si només té una classe (per definició, aquesta és tancada)

# Recurrència i transciència
- Temps d'impacte a $j$ des de $I$ és $$T_{ij}=\inf\{n\geq 1|X_{n}=j,X_{0}=i\}$$ i, per tant, es tracta d'una variable aleatòria que mesura el temps fins la primera vegada que es visita $j$ partint des de $i$.
	Es defineix el temps de retorn a $i$ com $T_{ii}=T_{i}$.

Com qualsevol variable aleatòria, podem definir una funció $$f_{ij}(n)=\mathbb P(T_{ij}= n)$$ i com $f_{ij}(n)$ només mesura la 1a vegada, es té que $$f_{ij}(n)\leq p_{ij}(n)$$
- Recurrent: $i\in S$ és recurrent si $\sum\limits_{n}f_{ij}(n)=1$. Altrament és transcient.
Observació $\mathbb P(T_{i}=\infty)=1-\int_{n\geq 1}f_{ii}(n)$ 
Per tant, $f$ és recurrent $\iff f$ és distribució de probabilitats: $$\mathbb P(T_{i}<\infty)=1$$ i és transcient $\iff$ hi ha una probabilitat no nula que mai torni a l'origen: $\mathbb P(T_{i}=\infty)=\infty$.

- Criteri alternatiu per recurrència: $i\in S$ és recurrent $\iff\sum\limits_{n\geq 1}p_{ii}(n)=\infty$.
- Teorema: Tots els estats d'una mateixa classe tenen el mateix comportament.

1. $C$ no tancat$\implies$ transcient.
2. $C$ tancada i finita $\implies$ recurrent.
3. $C$ tancada i infinita$\implies$ no se sap

# Recurrencia de camins aleatoris
## Teorema de Pólya 
AKA Teorema del borratxo.

El caminar aleatori sobre $\mathbb Z^{d}$ és recurrent $\iff d\leq 2$ 

# Temps de retorn esperat
El temps esperat de retorn és $$\mu_{i}=E(T_{i})=\sum\limits_{n}nf_{ii}(n)$$
- $i\in S$ és transient $\implies \mu_{i}=\infty$
- $i\in S$ és recurrent: hi ha dos possibles casos:
	- Positivament recurrent: $\mu_{i}<\infty$
	- Null-recurrent: $\mu_{i}=\infty$
Com els estats d'una classe tenen el mateix comportament, si $i\in C_{j}\in S$ es recurrent diem que $C_{j}$ és recurrent.

Proposició: $S$ és finit i $i\in S$ és recurrent $\implies$ $i\in S$ és positivament recurrent

# Probabilitat i temps d'impacte
## Probabilitat d'impacte
La probabilitat d'impacte a una classe tancada $C$ des de $i\in S$ és la probabilitat que si $X_{o}=i$ la cadena acabi a $C$: $$q_{i}=\mathbb P(C_{abs}|X_{o}=i)=\sum\limits_{j\in S}p_{ij}\mathbb P(C_{abs}|X_{o}=j)=\sum\limits_{j\in S}p_{ij}q_{j}$$
## Temps d'impacte
EL temps d'impacte esperat de $i\in S$ és l'esperança del temps que tarda a ser absorbit per alguna clase tancada: $$m_{i}=\mathbb E(\min T_{ij})$$
- Si $i\notin$ classe tancada: $m_{i}=1+\sum\limits_{j\in S}m_{j}p_{ij}$ 
- Si $i\in$ classe tancada: $m_{i}=0$

## Ruina del jugador
En la ruina del jugador la probabilitat d'impacte (i absorció) de l'estat 0 val: $$\large q_{i}=\begin{cases}
1-\frac i N\quad p=\frac 1 2 \\
\frac{b^{i}-b^{N}}{1-b^{N}}\quad p\neq \frac 1 2,b=\frac{1-p} p \\
\end{cases}$$
Jugant vs un casino ($N=\infty$): $q_{i}=1-\frac i N=1$ 
### Temps de ruina
Sigui $m_{i}$ l'esperança del temps d'absorció: $$m_{i}=\begin{cases}
i(N-i)\quad p=\frac 1 2 \\
\frac{1}{1-2p}(i-\frac{1-b^{i}}{1-b^{N}})\quad p\neq\frac 1 2
\end{cases}$$ on $b=\frac{1-p}{p}$

# Aperiodicitat
Sigui $i\in S$ un estat recurrent, el període $d(i)$ es defineix com: $$d(i)=mcd\{n|p_{ii}(n)>0\}$$
Observació: Com $i\in S$ és recurrent, el conjunt on fem el $mcd$ no és buit.

Proposició: la Periodicitat és una propietat de classe.

Classe aperiòdica: classe on el període dels seus estats és 1

Observació: Si hi ha un estat amb un llaç la classe és aperiòdica

# Distribucions estacionaries
Sigui $P$ la matriu de transició (pot arribar a ser $\infty$)
Diem que $\pi=(\pi_{1},\pi_{2},\dots)$ és una distribució de probabilitats si:
- És distribució de probabilitats: $\pi_{i}\geq 0,\sum\limits\pi_{i}=1$
- És estacionària: $\pi=\pi P$

Observacions: 
- La distribució estacionària és el VEP per l'esquerra de $P$ de VAP 1
- Si $P$ és $\infty$ la matriu es diu operador: $\pi=\pi P$ s'ha d'entendre com $\forall j\in S\quad\pi_{j}=\sum\limits_{i\in s}p_{ij}\pi_{i}$
- La dinàmica de la CdM ve donada a cada pas per la matriu $P$. Si estem en la distribució estacionària $P$ no farà res.
- La estacionaritat dona $|S|$ equacions i els axiomes de Kolmogorov donen 1 equació. El nombre de variables és $|S|$, per tant pot ser SI ($P-Id<|S|$), SCD o SCI.

## Equacions de balanceig
Sigui $S_{j}=S-\{j\}$ el conjunt de tots els estats menys el $j$:
- Si $\sum\limits_{i\in S_{j}}\pi_{j}p_{ji}=\sum\limits_{i\in S_{j}}\pi_{j}p_{ij}$ llavors $\pi$ compleix justicia global
- Si $\forall j\quad\pi_{j}p_{ji}=\pi_{i}p_{ij}$ llavors $\pi$ compleix justicia local
Si es compleix, aleshores $\pi$ és estacionària (suficient però no necessaris)

Proposició: diem que $P$ és doblement estocàstica si $P$ i $P^{T}$ són estocàstiques
	Si $P$ és doblement estocàstica i finita: $\pi$ és estacionària i es distribueix uniformement.

Teorema: Una CdM $X_{m}$ té distribució estacionària $\iff$ té alguna classe positivament recurrent. En particular, si $X_{n}$ és irreductible, aleshores $\pi$ és única i es compleix que: $$\pi_{i}=\frac 1{\mathbb E(T_{i})}$$ on $T_{i}$ és el $t$ de retorna a $i$.

# Teorema ergòdic
La distribució límit de $i\in S$, $\sigma^i$ es defineix per $$\sigma_{j}^{i}=\lim_{n\to\infty}p_{ij}(n)\quad\forall j\in S$$
- Teorema: Distribució límit $\implies$ distribució estacionària
Distribució ergòdica: ha de ser aperiòdica, irreductible i positiva-recurrent
	$|S|<\infty,X_{n}$ irreductible$\implies X_{n}$ pos-rec
	$P$ estocàstica$\implies\lambda_{1}=1\geq\lambda_{2}\geq\dots\geq\lambda_{m}\geq -1$ 
	Aperiòdica$\implies\lambda_{m}>-1$
	Irreductible$\implies\lambda_{2}<1$
## Teorema fonamental de les CdM
$X_{n}$ ergòdica$\implies\forall i,j\in S\quad\lim_{n}p_{ij}(n)=\pi_{j}$
Per qualsevol distribució inicial $\mu$: $\lim\mathbb P(X_{n}=j|X_{o}\sim\mu)=\pi_{j}$ 

### Monte Carlo Markov Chains
CdM on deixem passar un temps $t$ fins que la distribució s'apropa a la estacionària $\pi$. La velocitat de convergència és $O(\lambda^{n})$ on $\lambda=\max(|\lambda_{2}|,|\lambda_{m}|)$ 

