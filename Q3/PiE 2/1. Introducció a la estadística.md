- Estadística: ciencia que estudia les variables aleatòries
Les variables aleatòries poden ser:
	- Qualitatives (categòriques o factors)
	- Quantitatives, on es distingeixen les contínues i les discretes
- Suport: allà on la variable aleatòria pren valors
- Mostra: conjunt de dades extretes d'una variable aleatòria
	- Mostra aleatòria simple: totes les dades són independents una de l'altra
	$$\underset{\sim}x=(x_{1},\dots,x_{n})$$
# Estadística descriptiva
[[6. Població i mostra]]
Part de l'estadística que extreu informació de la mostra, dibuixant gràfiques i calculant estadístics
- Mitjana: $$\overline x=\frac 1 n\sum\limits_{i=1}^{n}x_{i}$$
- Moda: l'element amb major freqüècia relativa
- Mediana: L'element que, situat en un array ordenat, deixa el 50% a l'esquerra. 
- Variancia: $$S^{2}=\frac 1{n-1}\sum\limits_{i=1}^{n}(x_{i}-a)^{2}$$ Una altra fòrmula és $$Var(X)=E(X^{2})-E(X)^{2}$$
- Teorema central del límit: [[6. Població i mostra]]

Cinc distribucions ben importants són la Poisson, Bernoulli, Binomial, Exponencial, Normal: [[2. Variables aleatories]] 
# Estimació puntual
Si s'assumeix que $X\sim f(x;\theta)$ i $\underset\sim x$ és una mostra aleatoria simple de $X$, es pot estimar el valor del paràmetre $\theta$ puntualment.
- Mètode dels moments i mètode de màxima versemblança: [[6. Població i mostra]] 

## Propietats d'un estimador
- Sense biaix: $$E(\hat\theta)=\theta$$
- Mínima variancia: Si $\hat\theta$ és un estimador no esbiaixat de $\theta$ , llavors $$Var(\hat\theta)\geq\frac 1{I(\theta)}$$ on $I(\theta)$ és la matriu d'informació de Fischer: $$I(\theta)=E(-\frac{\partial^{2}}{\partial\theta^{2}}l)=E((\frac{\partial}{\partial\theta}l)^{2})$$
### Propietats de l'estimador de màxima versemblança
Sigui $\hat\theta$ l'estimador de màxima versemblança de $\theta$ , llavors $$\hat\theta\sim N(\theta,(I(\theta)^{-1})$$ cosa que implica:
- l'estimador de màxima versemblança és assimptoticament sense biaix
- l'estimador de màxima versemblança és assimptoticament de mínima variància
Observacions:
- $I(\theta)$ s'aproxima per $I(\hat\theta)$
- $I(\theta)$ cumpleix $$I_{n}(\theta)=I(\theta)·n$$ on $I_{n}(\theta)$ és la matriu d'informació associada a la mostra i $I(\theta)$ és la matriu d'informació d'una observació
# Distribucions relacionades amb la normal
## Chi quadrat $\mathcal X^{2}$ 
Siguin $Z_{1},\dots,Z_{n}$ VAIID amb $Z_{i}\sim N(0,1)$, $\mathcal X^{2}$ es defineix com $$y=\sum\limits_{i=1}^{n}Z_{i}^{2}\sim\mathcal X_{n}^{2}$$ on $n$ són els graus de llibertat.

Es tracta d'una funció contínua sobre $\mathbb R^{+}$ amb funció de distribució: $$f_{y}(x)=\frac 1 {\Gamma(\frac n 2)·2^{n/2}}·x^{\frac n 2 - 1}·e^{-x/2}$$ Aquesta distribució compleix:
- $E(Y)=n$
- $Var(Y)=2n$
- $n\to\infty\implies\mathcal X^{2}\sim N(n, 2n)$
- $$\frac{(n-1)S^{2}}{\sigma^{2}}\sim\mathcal X^{2}_{n-1}$$ on $S^{2}=\frac{1}{n-1}\sum\limits_{i=1}^{n}(x_{i}-x)^{2}$, per tant $\mathcal X^{2}$ és la distribució de $S^{2}$
- $$E(S^{2})=\sigma^{2}$$
## t-d'Student
Sigui $Z\sim N(0,1)$ i $Y\sim\mathcal X^{2}_{n}$ estocàsticament independents: $$T=\frac{Z}{\sqrt{\frac{Y}{n}}}\sim t_{n}$$
Es tracta d'una funció contínua en $\mathbb R$ amb funció de distribució $$f_{T}(x)=\frac{\Gamma(\frac{n+1}2)}{\Gamma(\frac n 2)}\frac 1 {\sqrt{n\pi}}\frac 1{(1`\frac{x^{2}}{n})^{\frac{n+1}2}}$$
Aquesta distribució compleix:
- $E(T)=0$
- $Var(T)=\frac n{n-2},\quad n\geq 3$
- $$\frac{\overline x-\mu}{s/\sqrt n}\sim t_{n-1}$$
## Distribució de Fisher
Si $X_{1}\sim\mathcal X^{2}_{n_{1}}$ i $X_{2}\sim\mathcal X^{2}_{n_{2}}$ independents: $$F=\frac{X_{1}/n_{1}}{X_{2}/n_{2}}\sim F_{n_{1},n_{2}}$$
Es tracta d'una funció contínua en $\mathbb R^{+}$ amb funció de distribució $$\large f_{F}(x)=\frac{\Gamma(\frac{n_{1}+n_{2}}{2})}{\Gamma(\frac{n_{1}}2)\Gamma(\frac{n_{2}}2)}\left(\frac {n_{1}}{n_{2}}\right)^{n_{1}/2}\frac{x^{\frac{n_{1}-2}{2}}}{(1+\frac{n_{1}}{n_{2}}x)^{\frac{n_{1}+n_{2}}{2}}}$$

Aquesta distribució compleix:
- $E(F)=\frac{n_{2}}{n_{2}-2},\quad n_{2}\geq 3$
- $Var(F)=2\frac{n_{2}}{(n_{2}-2)^{2}}\frac{n_{1}+2n_{2}}{n_{1}(n_{2}-4)}\quad n_{2}\geq 5$ 
- $$\frac{S_{1}^{2}/\sigma^{2}_{1}}{S_{2}^{2}/\sigma_{2}^{2}}\sim F_{n_{1}-1,n_{2}-1}$$
- Si es dona $\sigma_{1}^{2}=\sigma_{2}^{2}$: $$\frac{S_{1}^{2}}{S_{2}^{2}}=F_{n_{1}-1,n_{2}-1}$$