# Formules de Tartaglia-Cardano
Expressions que resolen de forma exacta polinomis de graus $2, 3, 4$ 

# Teorema de Abel
Per polinomis de grau $\geq 5$ no existeix cap expressió que doni un resultat exacte.
# Equació de Kepler
$$f(x)=a+x-b\sin(x)$$
# Solucions a funcions computacionalment
## Analíticament
Sigui $f(x)$ una funció contínua en $[a,b]$, troba $\alpha$ tal que $f(\alpha)=0$
## Computacionalment
Donat $\varepsilon>0$ (la tolerància), troba $c\in(a,b)$ tal que $f(x)=0$ on $x\in[c-\varepsilon,c+\varepsilon]$

### Bisecció: 
Sigui $f(x)$ contínua en l'interval $[a,b]$ on $f(a)·f(b)<0$, definim $I_{o}=[a_{o},b_{o}]=[a,b]$ i el seu punt mig $x_{o}=\frac{a_{0}+b_{0}}{2}$
- Si $f(a_{o})·f(x_{o})<0\to[a_{1},b_{1}]=[a_{0},x_{0}]$
- Si $f(b_{o})·f(x_{o})<0\to[a_{1},b_{1}]=[x_{0},b_{0}]$
i tornem a definir el punt mig $x_{1}=\frac{a_{1}+b_{1}}{2}$, repetint el procés indefinidament fins obtenir una tolerancia adequada, obtenida segons $$\varepsilon=\frac{|b_{k}-a_{k}|}{2}$$
La seqüència de punts migs $\{x_{0},x_{1},\dots\}$ tindrà un límit $$\lim_{k\to\infty}x_{k}$$ on $$|x_{k}-\alpha|<\frac{|b_{k}-a_{k}|}{2}$$
La seqüència serà convergent si $$|x_{k}-x_{k-1}|<\varepsilon\quad\forall k>K(\varepsilon)$$
- Residu: el valor de la funció en el punt mig de la $k$-èssima iteració $$|f(x_{k})|$$
- 
### Newton(Raphson)
Una recta amb angle $\beta$, pendent $m$ i tal que $f(A)=B$ té la funció $$y(x)=B+m(x-a),\quad m=\tan(\beta)$$
1. Considerar l'interval $[a,b]$ tal que $f(a)·f(b)<0$
2. Trobar el punt mig $x_{o}$
3. Trobar la recta pendent de $f(x_{o})$: $$y(x)=f(x_{o})+f'(x_{o})(x-x_{o})$$
4. Trobar la coordenada $x$ de $f(x_{o})=0$, anomenant-lo $x_{1}$ $$x_{1}=x_{0}-\frac{f(x_{o})}{f'(x_{o})}$$ més genèricament: $$x_{k+1}=x_{k}-\frac{f(x_{k})}{f'(x_{k})}$$
6. Si $x_{1}< x_{o}$: $a=x_{1}$, si $x_{o}<x_{1}$ : $b=x_{1}$
7. Repetir des del pas 2

- Problema: si el punt mig cau sobre un màxim/mínim, pot no funcionar

### Mètode de la corda
En comptes d'utilitzar la  derivada $f'(x)$ a cada iteració, s'utilitza una constant $q=\frac{f(b)-f(a)}{b-a}$ de manera que $$x_{k+1}=x_{k}-\frac{f(x_{k})}{q}$$
### Mètode de la secant
En comptes d'utilitzar una $q$ fixa a cada iteració, s'utilitza una $q_{k}$ variable $q_{k}=\frac{f(x_{k})-f(x_{k-1})}{x_{k}-x_{k-1}}$ de manera que $$x_{k+1}=x_{k}-\frac{f(x_{k})}{q_{k}}$$
# Ordre de convergència
Sigui $\{x_{k}\}$ una seqüència amb $\lim_{k\to\infty}x_{k}=\alpha$, la seqüència és d'ordre $p$ si $$\lim_{k\to\infty}\frac{|x_{k+1}-\alpha|}{|x_{k}-\alpha|^{p}}=C,\quad0<C<\infty$$ i particularment, si $p=1$, $C<1$

Sigui $\varepsilon_{k}=|x_{k}-\alpha|$, es pot reescriure la igualtat anterior com $$\varepsilon_{k+1}=C·\varepsilon_{k}^{p}$$ 

## Bisecció
La seqüència $\{x_{k}\}$ de l'algoritme de bisecció no és ni $p=1$, pero ho és assimptoticament

## Newton
És de l'ordre $p=2$

## Corda
$p=1$

## Secant
$p=\frac{1+\sqrt 5}{2}$
## Obtenció analítica de $p$
Si es té la seqüència $\{x_{k}\}$ però no l'algoritme, es pot obtenir l'ordre de convergència de la següent manera:

$$X_{k}=\log\varepsilon_{k}$$ $$Y_{k}=\log\varepsilon_{k+1}$$
$$Y_{k}=D+p·X_{k}$$ on $p$ és l'ordre de convergència. Per trobar-lo, haurem de fer una regressió lineal

# Factor de condició
Sigui una funció $f(x)$ i una constant $b\pm\Delta b$. Aquest $\Delta b$ induirà un error a les coordenades x $\Delta a$ segons $$\frac{\Delta b}{\Delta a}\approx f'(a)$$ quan $\Delta b$ és molt petit.

Reordenant s'obté $$|\Delta a| \approx\left|\frac 1{f'(a)}\right||\Delta b|$$
on $K=\left|\frac 1{f'(a)}\right|$

Com un algoritme té diversese operacions que poden amplificar l'error, generalment es diu que $$\varepsilon_{out}=K\varepsilon_{in}$$ on $\varepsilon_{out},\varepsilon_{in}$ són els errors d'entrada i sortida respectivament.